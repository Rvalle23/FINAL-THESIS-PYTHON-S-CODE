{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General:\n",
    "import tweepy           # To consume Twitter's API\n",
    "import pandas as pd     # To handle data\n",
    "import numpy as np      # For number computing\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn import decomposition\n",
    "\n",
    "# For plotting and visualization:\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ricardo/Desktop/TFG/CODIGO'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chardet\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Apr 05 16:55:17 +0000 2019</td>\n",
       "      <td>We’re coming for you Toyota</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Apr 05 16:55:18 +0000 2019</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Apr 05 16:55:20 +0000 2019</td>\n",
       "      <td>@dodiewill2 @Manic_Marge @Kristennetten @Chris...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Apr 05 16:55:17 +0000 2019   \n",
       "1  Fri Apr 05 16:55:18 +0000 2019   \n",
       "2  Fri Apr 05 16:55:20 +0000 2019   \n",
       "\n",
       "                                                text lang  \n",
       "0                        We’re coming for you Toyota   en  \n",
       "1  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en  \n",
       "2  @dodiewill2 @Manic_Marge @Kristennetten @Chris...   en  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landing = '/Users/ricardo/Desktop/TFG/CODIGO/TWEETS/'\n",
    "df = pd.read_csv(landing + 'Tesla 2019-04-05 185519.csv', encoding='utf-8',#ISO-8859-1\n",
    "                 names=['created_at', 'text', 'lang'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       en\n",
       "1       en\n",
       "2       en\n",
       "3       en\n",
       "4       en\n",
       "5       en\n",
       "6       en\n",
       "7       en\n",
       "8       en\n",
       "9       en\n",
       "10      en\n",
       "11      en\n",
       "12      en\n",
       "13      en\n",
       "14      en\n",
       "15      en\n",
       "16      en\n",
       "17      en\n",
       "18      en\n",
       "19      en\n",
       "20      en\n",
       "21      en\n",
       "22      en\n",
       "23      en\n",
       "24      en\n",
       "25      en\n",
       "26      en\n",
       "27      en\n",
       "28      en\n",
       "29      en\n",
       "        ..\n",
       "9489    en\n",
       "9490    en\n",
       "9491    en\n",
       "9492    en\n",
       "9493    en\n",
       "9494    en\n",
       "9495    en\n",
       "9496    en\n",
       "9497    en\n",
       "9498    en\n",
       "9499    en\n",
       "9500    en\n",
       "9501    en\n",
       "9502    en\n",
       "9503    en\n",
       "9504    en\n",
       "9505    en\n",
       "9506    en\n",
       "9507    en\n",
       "9508    en\n",
       "9509    en\n",
       "9510    en\n",
       "9511    en\n",
       "9512    en\n",
       "9513    en\n",
       "9514    en\n",
       "9515    en\n",
       "9516    en\n",
       "9517    en\n",
       "9518    en\n",
       "Name: lang, Length: 9519, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'].replace('en-gb','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>We’re coming for you Toyota</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dodiewill2 @Manic_Marge @Kristennetten @Chris...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               text lang\n",
       "0  2019-04-05                        We’re coming for you Toyota   en\n",
       "1  2019-04-05  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en\n",
       "2  2019-04-05  @dodiewill2 @Manic_Marge @Kristennetten @Chris...   en"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "for x in df['created_at']:\n",
    "    d = datetime.strptime(x,'%a %b %d %H:%M:%S %z %Y')\n",
    "    df['Date'] = d.date()\n",
    "\n",
    "del df['created_at']\n",
    "\n",
    "df = df[['Date', 'text', \"lang\"]]\n",
    "\n",
    "df.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>We’re coming for you Toyota</td>\n",
       "      <td>en</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dodiewill2 @Manic_Marge @Kristennetten @Chris...</td>\n",
       "      <td>en</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               text lang  len\n",
       "0  2019-04-05                        We’re coming for you Toyota   en   27\n",
       "1  2019-04-05  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en  140\n",
       "2  2019-04-05  @dodiewill2 @Manic_Marge @Kristennetten @Chris...   en  134"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'] = df['text'].str.len()\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Data cleaning process is similar to my previous project, but this time I added a long list of contraction to expand most of the contracted form to its original form such as \"don't\" to \"do not\". And this time, instead of Regex, I used Spacy to parse the documents, and filtered numbers, URL, punctuation, etc. Below are the steps I took to clean the tweets.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;1.Decoding: unicode_escape for extra \"\\\" before unicode character, then unidecode <br>\n",
    "&nbsp;&nbsp;&nbsp;2.Apostrophe handled: there are two characters people use for contraction. \"’\"(apostrophe) and \"'\"(single quote). If these two symbols are both used for contraction, it will be difficult to detect and properly map the right expanded form. So any \"’\"(apostrophe) is changed to \"'\"(single quote)<br>\n",
    "&nbsp;&nbsp;&nbsp;3.Contraction check: check if there's any contracted form, and replace it with its original form <br>\n",
    "&nbsp;&nbsp;&nbsp;4.Parsing: done with Spacy<br>\n",
    "&nbsp;&nbsp;&nbsp;5.Filtering punctuation, white space, numbers, URL using Spacy methods while keeping the text content of hashtag intact\n",
    "&nbsp;&nbsp;&nbsp;6.Removed @mention<br>\n",
    "&nbsp;&nbsp;&nbsp;7.Lemmatize: lemmatized each token using Spacy method '.lemma_'. Pronouns are kept as they are since Spacy lemmatizer transforms every pronoun to \"-PRON-\" <br>\n",
    "&nbsp;&nbsp;&nbsp;8.Special character removal<br>\n",
    "&nbsp;&nbsp;&nbsp;9.Single syllable token removal<br>\n",
    "&nbsp;&nbsp;&nbsp;10.Spell correction: it is a simple spell correction dealing with repeated characters such as \"sooooo goooood\". If the same character is repeated more than two times, it shortens the repetition to two. For example \"sooooo goooood\" will be transformed as \"soo good\". This is not a perfect solution since even after correction, in case of \"soo\", it is not a correct spelling. But at least it will help to reduce feature space by making \"sooo\", \"soooo\", \"sooooo\" to the same word \"soo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tthustla/yet_another_tiwtter_sentiment_analysis_part1/blob/master\n",
    "#/Yet_Another_Twitter_Sentiment_Analysis_part1-Copy1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "negations_dic = {\"RT\":\"\", \"rt\": \"\",\"lmao\":\"laughing my ass off\",\"wtf\":\"what the fuck\",\"I\":\"\",\"and\":\"\",\"to\":\"\",\n",
    "                 \"you\":\"\", \"he\":\"\", \"she\":\"\", \"it\":\"\",\"we\":\"\",\"lol\":\"laughing out loud\",\n",
    "                   \"on\":\"\",\"that\":\"\", \"at\":\"\", \"for\":\"\", \"us\":\"\", \"our\":\"\",\"in\":\"\",\n",
    "                   \"mine\":\"\",\"your\":\"\",\"them\":\"\",\"his\":\"\",\"her\":\"\",\"myself\":\"\",\"yourserlf\":\"\",\n",
    "                   \"hisself\":\"\", \"yours\":\"\", \"ours\":\"\", \"their\":\"\", \"those\":\"\", \"this\":\"\",\n",
    "                   \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \"ll\":\"will\",\n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                   \"here's\": \"here is\", \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "                   \"oh damn\":\"incredible\",\"whatcha\":\"what are you\",\"luv\":\"love\",\"sux\":\"sucks\",\"btw\":\"by the way\"}          \n",
    "\n",
    "\n",
    "SMILEY = {\":‑)\":\"smiley\",\":-]\":\"smiley\",\":-3\":\"smiley\",\":->\":\"smiley\",\"8-)\":\"smiley\",\":-}\":\"smiley\",\n",
    "        \":)\":\"smiley\",\":]\":\"smiley\",\":3\":\"smiley\",\":>\":\"smiley\",\"8)\":\"smiley\",\":}\":\"smiley\",\n",
    "         \":o)\":\"smiley\",\":c)\":\"smiley\",\":^)\":\"smiley\",\"=]\":\"smiley\",\"=)\":\"smiley\",\":-))\":\"smiley\",\n",
    "         \":‑D\":\"smiley\", \"8‑D\":\"smiley\",\"x‑D\":\"smiley\", \"X‑D\":\"smiley\",\":D\":\"smiley\",\"8D\":\"smiley\",\n",
    "         \"xD\":\"smiley\",\"XD\":\"smiley\",\":‑(\":\"sad\", \":‑c\":\"sad\", \":‑<\":\"sad\",\":‑[\":\"sad\",    \n",
    "         \":(\":\"sad\",\":c\":\"sad\",\":<\":\"sad\",\":[\":\"sad\", \":-||\":\"sad\",\">:[\":\"sad\",\":{\":\"sad\",\n",
    "         \":@\":\"sad\",\">:(\":\"sad\",\":‑(\":\"sad\",\":(\":\"sad\",\":‑P\":\"playful\",\"X‑P\":\"playful\",\n",
    "         \"x‑p\":\"playful\", \":‑p\":\"playful\", \":‑Þ\":\"playful\", \":‑þ\":\"playful\",\":‑b\":\"playful\",\n",
    "         \":P\":\"playful\",\"XP\":\"playful\", \"xp\":\"playful\",\":p\":\"playful\", \":Þ\":\"playful\",\":þ\":\"playful\", \n",
    "         \"ð¢\":\"cry\",\":b\":\"playful\",\"<3\":\"love\"}\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first issue is that, during the cleaning process, negation words are split into two parts, and the 't' after the apostrophe vanishes when I filter tokens with length more than one syllable. This makes words like \"can't\" end up as same as \"can\". This seems like not a trivial matter for sentiment analysis purpose.\n",
    "\n",
    "The second issue is that some of the URL links don't start with \"http\", sometimes people paste a link in \"www.aaaa.com\" form. This wasn't properly handled when I defined the URL address pattern as 'https?://[A-Za-z0-9./]+'. And another problem with this regex pattern is that it only detects alphabet, number, period, slash. This means it will fail to catch the part of the URL if it contains any other special character such as \"=\", \"_\", \"~\", etc.</n>\n",
    "\n",
    "The third issue is the regex pattern for Twitter ID. In the previous cleaning function I defined it as '@[A-Za-z0-9]+', but with a little googling, I found out that twitter ID also allows underscore symbol as a character can be used with ID. Except for underscore symbol, only characters allowed are alphabets and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ricardo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import itertools\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import Word \n",
    "\n",
    "corpus = []\n",
    "ps = PorterStemmer()\n",
    "sb_stemmer = SnowballStemmer(\"english\",)\n",
    "tok = WordPunctTokenizer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "\n",
    "    pat1 = r'(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)'\n",
    "    pat2 = r'https?://[^ ]+'\n",
    "    combined_pat = r'|'.join((pat1, pat2))\n",
    "    www_pat = r'www.[^ ]+'\n",
    "    neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "    ps = PorterStemmer()\n",
    "    tok = WordPunctTokenizer()\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "\n",
    "    tweet_1 = emoji.demojize(bom_removed)    \n",
    "        \n",
    "    stripped = re.sub(combined_pat, '', tweet_1)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    \n",
    "    # Standardizing words\n",
    "    tweet = ''.join(''.join(s)[:2] for _, s in itertools.groupby(neg_handled))\n",
    "    \n",
    "    #Deal with emojis  \n",
    "\n",
    "    words_1 = tweet.split()\n",
    "    reformed = [SMILEY[word] if word in SMILEY else word for word in words_1]\n",
    "    tweet = \" \".join(reformed)\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    words = [x for x in nltk.word_tokenize(letters_only) if len(x) > 1]\n",
    "    \n",
    "    #review = [sb_stemmer.stem(word) for word in words]\n",
    "    review_2 = [wnl.lemmatize(word) for word in words]\n",
    "    return (' '.join(review_2)).strip()\n",
    "\n",
    "# DO NOT REMOVE STOP WORDS FOR SENTIMENT ANALYSIS - OR AT LEAST NOT NEGATIVE ONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = [tweet_cleaner(t) for t in df['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     re coming toyota\n",
       "1    enforcement basically robinhood is the crowdfu...\n",
       "2                                       marge jeffreyr\n",
       "3        change screen preference from night mode auto\n",
       "4        stay tuned the live streaming pick the winner\n",
       "5    what have done team no confirmation noa seems ...\n",
       "6    fun drive mountain with great control regenera...\n",
       "7    exclusive united state set sight china new ele...\n",
       "8           literally baby who have been the planet mo\n",
       "9    my imaginary tesla after hitting the supercharger\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_clean'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMPIEZA DE OUTLIERS --> LOS REULSTADOS NO VARÍAN CASI NADA\n",
    "ESTO ESTA INTERESANTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Previously, we just removed commonly occurring words in a general sense. \n",
    "#We can also remove commonly occurring words from our text data First, \n",
    "#let’s check the 10 most frequently occurring words in our text data then\n",
    "#take call to remove or retain.\n",
    "\n",
    "freq = pd.Series(' '.join(df['text_clean']).split()).value_counts()[:5]\n",
    "print(freq)\n",
    "\n",
    "print(30*\"--\")\n",
    "\n",
    "freq = list(freq.index)\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['text_clean'].head()\n",
    "\n",
    "\n",
    "\n",
    "#Eliminate the uncommon noums that are mentioned and which do not give us any info\n",
    "freq = pd.Series(' '.join(df['text_clean']).split()).value_counts()[-100:]\n",
    "freq = list(freq.index)\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "df['text_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "http://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Utility function to classify the polarity of a tweet using textblob.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analize_sentiment_English(tweet):\n",
    "    \n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>len</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>We’re coming for you Toyota</td>\n",
       "      <td>en</td>\n",
       "      <td>27</td>\n",
       "      <td>re coming toyota</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>enforcement basically robinhood is the crowdfu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dodiewill2 @Manic_Marge @Kristennetten @Chris...</td>\n",
       "      <td>en</td>\n",
       "      <td>134</td>\n",
       "      <td>marge jeffreyr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @elonmusk: @SherylCrow @Tesla Change your s...</td>\n",
       "      <td>en</td>\n",
       "      <td>86</td>\n",
       "      <td>change screen preference from night mode auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @justinsuntron: Stay tuned for the live str...</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>stay tuned the live streaming pick the winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @M3Exp: What have you DONE, ⁦@Tesla⁩ team a...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>what have done team no confirmation noa seems ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @tarunemany: Fun to drive in mountains with...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>fun drive mountain with great control regenera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Exclusive: United States sets sights on China ...</td>\n",
       "      <td>en</td>\n",
       "      <td>111</td>\n",
       "      <td>exclusive united state set sight china new ele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@DickWinchester @Sublux8tor @kulpability @alex...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>literally baby who have been the planet mo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>my imaginary Tesla after hitting the supercharger</td>\n",
       "      <td>en</td>\n",
       "      <td>49</td>\n",
       "      <td>my imaginary tesla after hitting the supercharger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Currently charging my battery... Charged to 74...</td>\n",
       "      <td>en</td>\n",
       "      <td>70</td>\n",
       "      <td>currently charging my battery charged</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @elonmusk: “…drivers in this dataset use Au...</td>\n",
       "      <td>en</td>\n",
       "      <td>139</td>\n",
       "      <td>driver dataset use autopilot of driven mile ye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>SELLing $TSLA here!\\n\\n-over 50% downside to p...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>selling tsla here over downside pt musk irresp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@markbspiegel Have been saying this for years....</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>have been saying year tsla is first very forem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dpolner @scottwillpenn @Trumpery45 @LivingTes...</td>\n",
       "      <td>en</td>\n",
       "      <td>139</td>\n",
       "      <td>drinking don but drink the toilet boy</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @lloydalter: Tesla adds 2 new video games, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>tesla add new video game super breakout it big...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Satisfying read, Shorty fools</td>\n",
       "      <td>en</td>\n",
       "      <td>29</td>\n",
       "      <td>satisfying read shorty fool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @CNET: Tesla adds more Atari games to its d...</td>\n",
       "      <td>en</td>\n",
       "      <td>103</td>\n",
       "      <td>tesla add more atari game it dashboard joystick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@KurtHellyn @lhansen0 @Tesla @Model3Owners @rr...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>ryan glad a an investor a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @justinsuntron: Stay tuned for the live str...</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>stay tuned the live streaming pick the winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               text lang  len  \\\n",
       "0   2019-04-05                        We’re coming for you Toyota   en   27   \n",
       "1   2019-04-05  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en  140   \n",
       "2   2019-04-05  @dodiewill2 @Manic_Marge @Kristennetten @Chris...   en  134   \n",
       "3   2019-04-05  RT @elonmusk: @SherylCrow @Tesla Change your s...   en   86   \n",
       "4   2019-04-05  RT @justinsuntron: Stay tuned for the live str...   en  124   \n",
       "5   2019-04-05  RT @M3Exp: What have you DONE, ⁦@Tesla⁩ team a...   en  140   \n",
       "6   2019-04-05  RT @tarunemany: Fun to drive in mountains with...   en  140   \n",
       "7   2019-04-05  Exclusive: United States sets sights on China ...   en  111   \n",
       "8   2019-04-05  @DickWinchester @Sublux8tor @kulpability @alex...   en  140   \n",
       "9   2019-04-05  my imaginary Tesla after hitting the supercharger   en   49   \n",
       "10  2019-04-05  Currently charging my battery... Charged to 74...   en   70   \n",
       "11  2019-04-05  RT @elonmusk: “…drivers in this dataset use Au...   en  139   \n",
       "12  2019-04-05  SELLing $TSLA here!\\n\\n-over 50% downside to p...   en  140   \n",
       "13  2019-04-05  @markbspiegel Have been saying this for years....   en  140   \n",
       "14  2019-04-05  @dpolner @scottwillpenn @Trumpery45 @LivingTes...   en  139   \n",
       "15  2019-04-05  RT @lloydalter: Tesla adds 2 new video games, ...   en  140   \n",
       "16  2019-04-05                      Satisfying read, Shorty fools   en   29   \n",
       "17  2019-04-05  RT @CNET: Tesla adds more Atari games to its d...   en  103   \n",
       "18  2019-04-05  @KurtHellyn @lhansen0 @Tesla @Model3Owners @rr...   en  140   \n",
       "19  2019-04-05  RT @justinsuntron: Stay tuned for the live str...   en  124   \n",
       "\n",
       "                                           text_clean  SA  \n",
       "0                                    re coming toyota   0  \n",
       "1   enforcement basically robinhood is the crowdfu...   1  \n",
       "2                                      marge jeffreyr   0  \n",
       "3       change screen preference from night mode auto   0  \n",
       "4       stay tuned the live streaming pick the winner   1  \n",
       "5   what have done team no confirmation noa seems ...   0  \n",
       "6   fun drive mountain with great control regenera...   1  \n",
       "7   exclusive united state set sight china new ele...   1  \n",
       "8          literally baby who have been the planet mo   0  \n",
       "9   my imaginary tesla after hitting the supercharger   0  \n",
       "10              currently charging my battery charged   0  \n",
       "11  driver dataset use autopilot of driven mile ye...   1  \n",
       "12  selling tsla here over downside pt musk irresp...   0  \n",
       "13  have been saying year tsla is first very forem...   1  \n",
       "14              drinking don but drink the toilet boy  -1  \n",
       "15  tesla add new video game super breakout it big...   1  \n",
       "16                        satisfying read shorty fool   1  \n",
       "17    tesla add more atari game it dashboard joystick   1  \n",
       "18                          ryan glad a an investor a   1  \n",
       "19      stay tuned the live streaming pick the winner   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['SA'] = np.array([ analize_sentiment_English(tweet) for tweet in df['text_clean'] ])\n",
    "display(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive tweets: 39.00619813005568%\n",
      "Percentage of neutral tweets: 42.66204433238786%\n",
      "Percentage de negative tweets: 18.331757537556467%\n"
     ]
    }
   ],
   "source": [
    "# We construct lists with classified tweets:\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(df['text_clean']) if df['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(df['text_clean']) if df['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(df['text_clean']) if df['SA'][index] < 0]\n",
    "\n",
    "# We print percentages:\n",
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(df['text_clean'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(df['text_clean'])))\n",
    "print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(df['text_clean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9519"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"{0:.2f}%\".format(df[\"SA\"].mean() *100))\n",
    "len(df.SA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>len</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>We’re coming for you Toyota</td>\n",
       "      <td>en</td>\n",
       "      <td>27</td>\n",
       "      <td>re coming toyota</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>enforcement basically robinhood is the crowdfu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dodiewill2 @Manic_Marge @Kristennetten @Chris...</td>\n",
       "      <td>en</td>\n",
       "      <td>134</td>\n",
       "      <td>marge jeffreyr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @elonmusk: @SherylCrow @Tesla Change your s...</td>\n",
       "      <td>en</td>\n",
       "      <td>86</td>\n",
       "      <td>change screen preference from night mode auto</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @justinsuntron: Stay tuned for the live str...</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>stay tuned the live streaming pick the winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @M3Exp: What have you DONE, ⁦@Tesla⁩ team a...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>what have done team no confirmation noa seems ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @tarunemany: Fun to drive in mountains with...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>fun drive mountain with great control regenera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Exclusive: United States sets sights on China ...</td>\n",
       "      <td>en</td>\n",
       "      <td>111</td>\n",
       "      <td>exclusive united state set sight china new ele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@DickWinchester @Sublux8tor @kulpability @alex...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>literally baby who have been the planet mo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>my imaginary Tesla after hitting the supercharger</td>\n",
       "      <td>en</td>\n",
       "      <td>49</td>\n",
       "      <td>my imaginary tesla after hitting the supercharger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                               text lang  len  \\\n",
       "0  2019-04-05                        We’re coming for you Toyota   en   27   \n",
       "1  2019-04-05  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en  140   \n",
       "2  2019-04-05  @dodiewill2 @Manic_Marge @Kristennetten @Chris...   en  134   \n",
       "3  2019-04-05  RT @elonmusk: @SherylCrow @Tesla Change your s...   en   86   \n",
       "4  2019-04-05  RT @justinsuntron: Stay tuned for the live str...   en  124   \n",
       "5  2019-04-05  RT @M3Exp: What have you DONE, ⁦@Tesla⁩ team a...   en  140   \n",
       "6  2019-04-05  RT @tarunemany: Fun to drive in mountains with...   en  140   \n",
       "7  2019-04-05  Exclusive: United States sets sights on China ...   en  111   \n",
       "8  2019-04-05  @DickWinchester @Sublux8tor @kulpability @alex...   en  140   \n",
       "9  2019-04-05  my imaginary Tesla after hitting the supercharger   en   49   \n",
       "\n",
       "                                          text_clean  SA  \n",
       "0                                   re coming toyota   0  \n",
       "1  enforcement basically robinhood is the crowdfu...   1  \n",
       "2                                     marge jeffreyr   0  \n",
       "3      change screen preference from night mode auto   0  \n",
       "4      stay tuned the live streaming pick the winner   1  \n",
       "5  what have done team no confirmation noa seems ...   0  \n",
       "6  fun drive mountain with great control regenera...   1  \n",
       "7  exclusive united state set sight china new ele...   1  \n",
       "8         literally baby who have been the planet mo   0  \n",
       "9  my imaginary tesla after hitting the supercharger   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['SA'] = np.array([ analize_sentiment_English(tweet)\n",
    "                     for tweet in df['text_clean'] ])\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND ANALYSIS: GETTING RID OF THE NEUTRAL TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new data frame in which w eget rid from the sentiment anañysis which value is = equal 0 or neutral in order to leave only the positive and negative sentiment tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analize_sentiment_English(tweet):\n",
    "    \n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data = df    \n",
    "del data[\"SA\"]    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a knowledge on how the tweets are psotive or negative in term of the total and then, we just can start using the new data frame to test the new results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>len</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@Yeomen23 @TeslaCharts @SEC_Enforcement Basica...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>enforcement basically robinhood is the crowdfu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @justinsuntron: Stay tuned for the live str...</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>stay tuned the live streaming pick the winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @tarunemany: Fun to drive in mountains with...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>fun drive mountain with great control regenera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Exclusive: United States sets sights on China ...</td>\n",
       "      <td>en</td>\n",
       "      <td>111</td>\n",
       "      <td>exclusive united state set sight china new ele...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @elonmusk: “…drivers in this dataset use Au...</td>\n",
       "      <td>en</td>\n",
       "      <td>139</td>\n",
       "      <td>driver dataset use autopilot of driven mile ye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@markbspiegel Have been saying this for years....</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>have been saying year tsla is first very forem...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@dpolner @scottwillpenn @Trumpery45 @LivingTes...</td>\n",
       "      <td>en</td>\n",
       "      <td>139</td>\n",
       "      <td>drinking don but drink the toilet boy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @lloydalter: Tesla adds 2 new video games, ...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>tesla add new video game super breakout it big...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>Satisfying read, Shorty fools</td>\n",
       "      <td>en</td>\n",
       "      <td>29</td>\n",
       "      <td>satisfying read shorty fool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @CNET: Tesla adds more Atari games to its d...</td>\n",
       "      <td>en</td>\n",
       "      <td>103</td>\n",
       "      <td>tesla add more atari game it dashboard joystick</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>@KurtHellyn @lhansen0 @Tesla @Model3Owners @rr...</td>\n",
       "      <td>en</td>\n",
       "      <td>140</td>\n",
       "      <td>ryan glad a an investor a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @justinsuntron: Stay tuned for the live str...</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>stay tuned the live streaming pick the winner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @europe_tron: Great Move @justinsuntron 😀👍🏽...</td>\n",
       "      <td>en</td>\n",
       "      <td>70</td>\n",
       "      <td>tron great move grinning face thumb up medium ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>RT @elonmusk: “…drivers in this dataset use Au...</td>\n",
       "      <td>en</td>\n",
       "      <td>139</td>\n",
       "      <td>driver dataset use autopilot of driven mile ye...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>$TSLA =The Worst &amp;amp; Most MANIPULATED stock ...</td>\n",
       "      <td>en</td>\n",
       "      <td>148</td>\n",
       "      <td>tsla the worst most manipulated stock by manag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                                               text lang  len  \\\n",
       "1   2019-04-05  @Yeomen23 @TeslaCharts @SEC_Enforcement Basica...   en  140   \n",
       "4   2019-04-05  RT @justinsuntron: Stay tuned for the live str...   en  124   \n",
       "6   2019-04-05  RT @tarunemany: Fun to drive in mountains with...   en  140   \n",
       "7   2019-04-05  Exclusive: United States sets sights on China ...   en  111   \n",
       "11  2019-04-05  RT @elonmusk: “…drivers in this dataset use Au...   en  139   \n",
       "13  2019-04-05  @markbspiegel Have been saying this for years....   en  140   \n",
       "14  2019-04-05  @dpolner @scottwillpenn @Trumpery45 @LivingTes...   en  139   \n",
       "15  2019-04-05  RT @lloydalter: Tesla adds 2 new video games, ...   en  140   \n",
       "16  2019-04-05                      Satisfying read, Shorty fools   en   29   \n",
       "17  2019-04-05  RT @CNET: Tesla adds more Atari games to its d...   en  103   \n",
       "18  2019-04-05  @KurtHellyn @lhansen0 @Tesla @Model3Owners @rr...   en  140   \n",
       "19  2019-04-05  RT @justinsuntron: Stay tuned for the live str...   en  124   \n",
       "20  2019-04-05  RT @europe_tron: Great Move @justinsuntron 😀👍🏽...   en   70   \n",
       "23  2019-04-05  RT @elonmusk: “…drivers in this dataset use Au...   en  139   \n",
       "24  2019-04-05  $TSLA =The Worst &amp; Most MANIPULATED stock ...   en  148   \n",
       "\n",
       "                                           text_clean  SA  \n",
       "1   enforcement basically robinhood is the crowdfu...   1  \n",
       "4       stay tuned the live streaming pick the winner   1  \n",
       "6   fun drive mountain with great control regenera...   1  \n",
       "7   exclusive united state set sight china new ele...   1  \n",
       "11  driver dataset use autopilot of driven mile ye...   1  \n",
       "13  have been saying year tsla is first very forem...   1  \n",
       "14              drinking don but drink the toilet boy   0  \n",
       "15  tesla add new video game super breakout it big...   1  \n",
       "16                        satisfying read shorty fool   1  \n",
       "17    tesla add more atari game it dashboard joystick   1  \n",
       "18                          ryan glad a an investor a   1  \n",
       "19      stay tuned the live streaming pick the winner   1  \n",
       "20  tron great move grinning face thumb up medium ...   1  \n",
       "23  driver dataset use autopilot of driven mile ye...   1  \n",
       "24  tsla the worst most manipulated stock by manag...   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['SA'] = np.array([ analize_sentiment_English(tweet) for tweet in data['text_clean'] ])  \n",
    "\n",
    "data = data[data.SA!= -1]\n",
    "\n",
    "display(data.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siendo 0 el extremo negativo y 1 el positivo, hoy tenemos\n",
      "que el sentimiento en los tweets sobre TSLA es de: 68.03 %\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Siendo 0 el extremo negativo y 1 el positivo, hoy tenemos\n",
    "que el sentimiento en los tweets sobre TSLA es de: {0:.2f} %\"\"\".format(data[\"SA\"].mean() * 100))\n",
    "\n",
    "#data.to_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative Tweets {0} and positive Tweets {1} :\n",
      "0    1745\n",
      "1    3713\n",
      "dtype: int64\n",
      "____________________________________________________________\n",
      "\n",
      "\n",
      "Percentage of positive tweets: 68.03%\n",
      "Percentage de negative tweets: 31.97%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of negative Tweets {0} and positive Tweets {1} :\")\n",
    "x = pd.value_counts(data['SA'].values, sort=False)\n",
    "print (x)\n",
    "\n",
    "print(30*\"__\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Percentage of positive tweets: {0:.2f}%\".format(len(pos_tweets)*100/len(data['text_clean'])))\n",
    "print(\"Percentage de negative tweets: {0:.2f}%\".format(len(neg_tweets)*100/len(data['text_clean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "pandas 0.23.4\n",
      "numpy 1.14.2\n",
      "datetime unknown\n",
      "matplotlib 3.0.2\n",
      "pandas_datareader 0.7.0\n",
      "fix_yahoo_finance 0.0.22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>270.260010</td>\n",
       "      <td>264.429993</td>\n",
       "      <td>264.440002</td>\n",
       "      <td>267.769989</td>\n",
       "      <td>7350900</td>\n",
       "      <td>267.769989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>275.369995</td>\n",
       "      <td>268.179993</td>\n",
       "      <td>268.750000</td>\n",
       "      <td>274.829987</td>\n",
       "      <td>8779200</td>\n",
       "      <td>274.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>280.329987</td>\n",
       "      <td>275.100006</td>\n",
       "      <td>277.160004</td>\n",
       "      <td>278.619995</td>\n",
       "      <td>6774100</td>\n",
       "      <td>278.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29</th>\n",
       "      <td>280.160004</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>278.700012</td>\n",
       "      <td>279.859985</td>\n",
       "      <td>5991300</td>\n",
       "      <td>279.859985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>289.200012</td>\n",
       "      <td>281.279999</td>\n",
       "      <td>282.619995</td>\n",
       "      <td>289.179993</td>\n",
       "      <td>8110400</td>\n",
       "      <td>289.179993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-02</th>\n",
       "      <td>289.440002</td>\n",
       "      <td>283.880005</td>\n",
       "      <td>288.299988</td>\n",
       "      <td>285.880005</td>\n",
       "      <td>5478900</td>\n",
       "      <td>285.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-03</th>\n",
       "      <td>296.170013</td>\n",
       "      <td>287.170013</td>\n",
       "      <td>287.320007</td>\n",
       "      <td>291.809998</td>\n",
       "      <td>7929900</td>\n",
       "      <td>291.809998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04</th>\n",
       "      <td>271.200012</td>\n",
       "      <td>260.589996</td>\n",
       "      <td>261.890015</td>\n",
       "      <td>267.779999</td>\n",
       "      <td>23699500</td>\n",
       "      <td>267.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-05</th>\n",
       "      <td>276.100006</td>\n",
       "      <td>266.114990</td>\n",
       "      <td>269.859985</td>\n",
       "      <td>274.959991</td>\n",
       "      <td>13032026</td>\n",
       "      <td>274.959991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2019-03-26  270.260010  264.429993  264.440002  267.769989   7350900   \n",
       "2019-03-27  275.369995  268.179993  268.750000  274.829987   8779200   \n",
       "2019-03-28  280.329987  275.100006  277.160004  278.619995   6774100   \n",
       "2019-03-29  280.160004  274.500000  278.700012  279.859985   5991300   \n",
       "2019-04-01  289.200012  281.279999  282.619995  289.179993   8110400   \n",
       "2019-04-02  289.440002  283.880005  288.299988  285.880005   5478900   \n",
       "2019-04-03  296.170013  287.170013  287.320007  291.809998   7929900   \n",
       "2019-04-04  271.200012  260.589996  261.890015  267.779999  23699500   \n",
       "2019-04-05  276.100006  266.114990  269.859985  274.959991  13032026   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2019-03-26  267.769989  \n",
       "2019-03-27  274.829987  \n",
       "2019-03-28  278.619995  \n",
       "2019-03-29  279.859985  \n",
       "2019-04-01  289.179993  \n",
       "2019-04-02  285.880005  \n",
       "2019-04-03  291.809998  \n",
       "2019-04-04  267.779999  \n",
       "2019-04-05  274.959991  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import watermark\n",
    "import fix_yahoo_finance\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,datetime,matplotlib,pandas_datareader,fix_yahoo_finance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data as pdr\n",
    "tsla = pdr.get_data_yahoo('TSLA', \n",
    "                          start=datetime.datetime(2019,3 , 26), \n",
    "                          end=datetime.datetime(2019, 4, 5))\n",
    "tsla.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tsla[\"High\"]\n",
    "del tsla[\"Low\"]\n",
    "del tsla[\"Open\"]\n",
    "del tsla[\"Volume\"]\n",
    "del tsla[\"Close\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clossing Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>267.769989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>274.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>278.619995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29</th>\n",
       "      <td>279.859985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Clossing Price\n",
       "Date                      \n",
       "2019-03-26      267.769989\n",
       "2019-03-27      274.829987\n",
       "2019-03-28      278.619995\n",
       "2019-03-29      279.859985"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla.rename(columns={'Adj Close': 'Clossing Price'}, inplace=True)\n",
    "tsla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "cont = 0\n",
    "\n",
    "for x in tsla[\"Clossing Price\"]: \n",
    "    y = (\"P{0}\".format(cont))\n",
    "    tsla[\"Closing Price\"][cont] = y \n",
    "    cont = cont + 1\n",
    "    \n",
    "tsla[\"SA\"] = \"[0,1]\"\n",
    "tsla[\"Result\"] = \"✅ or ❌\"\n",
    "\n",
    "\n",
    "del tsla[\"Clossing Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Closing Price</th>\n",
       "      <th>SA</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-26</th>\n",
       "      <td>P0</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>✅ or ❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-27</th>\n",
       "      <td>P1</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>✅ or ❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28</th>\n",
       "      <td>P2</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>✅ or ❌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Closing Price     SA  Result\n",
       "Date                                   \n",
       "2019-03-26            P0  [0,1]  ✅ or ❌\n",
       "2019-03-27            P1  [0,1]  ✅ or ❌\n",
       "2019-03-28            P2  [0,1]  ✅ or ❌"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "Noticed that our classes are imbalanced, and the ratio of negative to positive instances is 30:70.\n",
    "One of the tactics of combating imbalanced classes is using Decision Tree algorithms, so, we are using Random Forest classifier to learn imbalanced data and set class_weight=balanced.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has total 1089 entries with 25.44% negative, 74.56% positive\n",
      "Test set has total 363 entries with 24.52% negative, 75.48% positive\n",
      "Result for trigram with stop words (Tfidf)\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "            criterion='gini', max_depth=None, max_features='auto',\n",
      "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators='warn', n_jobs=None, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "\n",
      "Test result for 10000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 83.20%\n",
      "Test result for 15001 features\n",
      "accuracy score: 84.02%\n",
      "Test result for 20002 features\n",
      "accuracy score: 84.85%\n",
      "Test result for 25003 features\n",
      "accuracy score: 85.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.44      0.60        89\n",
      "    positive       0.85      1.00      0.91       274\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       363\n",
      "   macro avg       0.91      0.72      0.76       363\n",
      "weighted avg       0.88      0.86      0.84       363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.text\n",
    "y = data.SA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_train),\n",
    "                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n",
    "                                                                        (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))\n",
    "print(\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_test),\n",
    "                                                                             (len(X_test[y_test == 0]) / (len(X_test)*1.))*100,\n",
    "                                                                            (len(X_test[y_test == 1]) / (len(X_test)*1.))*100))\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    return accuracy\n",
    "\n",
    "cv = CountVectorizer()\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "n_features = np.arange(10000,30001,5001)\n",
    "def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=rf):\n",
    "    result = []\n",
    "    print(classifier)\n",
    "    print(\"\\n\")\n",
    "    for n in n_features:\n",
    "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        print(\"Test result for {} features\".format(n))\n",
    "        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n",
    "        result.append((n,nfeature_accuracy))\n",
    "    return result\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "print(\"Result for trigram with stop words (Tfidf)\\n\")\n",
    "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer', cv),\n",
    "        ('classifier', rf)\n",
    "    ])\n",
    "sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "y_pred = sentiment_fit.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['negative','positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML | Chi-square Test for feature selection\n",
    "\n",
    "Feature selection is also known as attribute selection is a process of extracting the most relevant features from the dataset and then applying machine learning algorithms for the better performance of the model. A large number of irrelevant features increases the training time exponentially and increase the risk of overfitting.\n",
    "\n",
    "Chi-square Test for Feature Extraction: \n",
    "Chi-square test is used for categorical features in a dataset. We calculate Chi-square between each feature and the target and select the desired number of features with best Chi-square scores. It determines if the association between two categorical variables of the sample would reflect their real association in the population.\n",
    "Chi- square score is given by (PHOTO) :\n",
    "https://cdncontribute.geeksforgeeks.org/wp-content/uploads/Capture-214.png![image.png](attachment:image.png)\n",
    "\n",
    "We will calculate the Chi square scores for all the features and visualize the top 20, here terms or words or N-grams are features, and positive and negative are two classes. given a feature X, we can use Chi square test to evaluate its importance to distinguish the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ST:\n",
    "\n",
    "To classify sentiment, we remove neutral score 0, then group score -1 and 1 to positive (TRUE), and score -1 to negative (FALSE). After simple cleaning up, this is the data we are going to work with.\n",
    "\n",
    "If you consider how chi2 is calculated, it will not only score highly on terms predictive of positive class but also score highly on terms predictive of negative class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(inplace=True)\n",
    "#df[df['SA'] != 0]\n",
    "#df['SA'] = np.logical_or(df['SA'] > 0,df['SA']<0)\n",
    "#cols = ['SA']\n",
    "#df.drop(cols, axis=1, inplace=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "tfidf = TfidfVectorizer(max_features=100000,ngram_range=(1, 1))\n",
    "X_tfidf = tfidf.fit_transform(df.text_clean)\n",
    "y = df.SA\n",
    "chi2score = chi2(X_tfidf, y)[0]\n",
    "plt.figure(figsize=(16,8))\n",
    "scores = list(zip(tfidf.get_feature_names(), chi2score))\n",
    "chi2 = sorted(scores, key=lambda x:x[1])\n",
    "topchi2 = list(zip(*chi2[-20:]))\n",
    "x = range(len(topchi2[1]))\n",
    "labels = topchi2[0]\n",
    "plt.barh(x,topchi2[1], align='center', alpha=0.5)\n",
    "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
    "plt.yticks(x, labels)\n",
    "plt.xlabel('$\\chi^2$')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Framework\n",
    "\n",
    "Pad sequences:\n",
    "\n",
    "In order to feed this data into our RNN, all input documents must have the same length. We will limit the maximum review length to max_words by truncating longer reviews and padding shorter reviews with a null value (0). We can accomplish this using the pad_sequences() function in Keras. For now, set max_words Then, I define the number of max features as 30000 and use Tokenizer to vectorize and convert text into Sequences so the Network can deal with it as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2214, 34) (2214, 2)\n",
      "(739, 34) (739, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras_preprocessing/text.py:178: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "max_fatures = 30000\n",
    "tokenizer = Tokenizer(nb_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data[\"text_clean\"].values)\n",
    "X1 = tokenizer.texts_to_sequences(data[\"text_clean\"].values)\n",
    "X1 = pad_sequences(X1)\n",
    "Y1 = pd.get_dummies(data[\"SA\"]).values\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1,Y1, random_state = 42)\n",
    "print(X1_train.shape,Y1_train.shape)\n",
    "print(X1_test.shape,Y1_test.shape)\n",
    "\n",
    "#SUM OF BOTH is the total number of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network \n",
    "\n",
    "\n",
    "Remember that our input is a sequence of words (technically, integer word IDs) of maximum length = max_words, and our output is a binary sentiment label (0 or 1).\n",
    "\n",
    "\n",
    "Keras offers an Embedding layer that can be used for neural networks on text data.\n",
    "It requires that the input data be integer encoded, so that each word is represented by a unique integer. This data preparation step can be performed using the Tokenizer API also provided with Keras.\n",
    "\n",
    "The Embedding layer is initialized with random weights and will learn an embedding for all of the words in the training dataset.\n",
    "\n",
    "It is a flexible layer that can be used in a variety of ways, such as:\n",
    "It can be used alone to learn a word embedding that can be saved and used in another model later.\n",
    "\n",
    "It can be used as part of a deep learning model where the embedding is learned along with the model itself.\n",
    "\n",
    "It can be used to load a pre-trained word embedding model, a type of transfer learning.\n",
    "\n",
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "It must specify 3 arguments:\n",
    "\n",
    "input_dim: This is the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0–10, then the size of the vocabulary would be 11 words.\n",
    "\n",
    "output_dim: This is the size of the vector space in which words will be embedded. It defines the size of the output vectors from this layer for each word. For example, it could be 32 or 100 or even larger. Test different values for your problem.\n",
    "\n",
    "input_length: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "For example, below we define an Embedding layer with a vocabulary of 200 (e.g. integer encoded words from 0 to 199, inclusive), a vector space of 32 dimensions in which words will be embedded, and input documents that have 50 words each.\n",
    "\n",
    "e = Embedding(200, 32, input_length=50)\n",
    "\n",
    "The Embedding layer has weights that are learned. If you save your model to file, this will include weights for the Embedding layer.The output of the Embedding layer is a 2D vector with one embedding for each word in the input sequence of words (input document).\n",
    "If you wish to connect a Dense layer directly to an Embedding layer, you must first flatten the 2D output matrix to a 1D vector using the Flatten layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 150\n",
    "lstm_out = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(200, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 34, 150)           4500000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 200)               280800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 4,781,202\n",
      "Trainable params: 4,781,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embed_dim,input_length = X1.shape[1], dropout=0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U=0.2,dropout_W=0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate our model \n",
    "\n",
    "We first need to compile our model by specifying the loss function and optimizer we want to use while training, as well as any evaluation metrics we’d like to measure. Specify the appropriate parameters, including at least one metric ‘accuracy’.\n",
    "\n",
    "Once compiled, we can kick off the training process. There are two important training parameters that we have to specify — batch size and number of training epochs, which together with our model architecture determine the total training time.\n",
    "\n",
    "Finally measuring the number of correct guesses. It is clear that finding negative tweets goes very well for the Network but deciding whether is positive is not really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(X1_train, Y1_train, nb_epoch = 3, batch_size=batch_size, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,acc = model.evaluate(X1_test, Y1_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnt, neg_cnt, pos_correct, neg_correct = 0, 0, 0, 0\n",
    "for x in range(len(X1_test)):\n",
    "    \n",
    "    result = model.predict(X1_test[x].reshape(1,X1_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "   \n",
    "    if np.argmax(result) == np.argmax(Y1_test[x]):\n",
    "        if np.argmax(Y1_test[x]) == 0:\n",
    "            neg_correct += 1\n",
    "        else:\n",
    "            pos_correct += 1\n",
    "       \n",
    "    if np.argmax(Y1_test[x]) == 0:\n",
    "        neg_cnt += 1\n",
    "    else:\n",
    "        pos_cnt += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"pos_acc\", pos_correct/pos_cnt*100, \"%\")\n",
    "print(\"neg_acc\", neg_correct/neg_cnt*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
